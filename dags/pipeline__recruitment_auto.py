"""
Generated DAG: pipeline__recruitment_auto

================================================================================
ðŸ‘¶ ì–´ë¦°ì´ë¥¼ ìœ„í•œ 100% ì´í•´ ê°€ëŠ¥ ì„¤ëª…ì„œ (Kindergarten Guide) ðŸ‘¶
================================================================================

ì•ˆë…•! ì´ íŒŒì¼ì€ "ì±„ìš© ê³µê³  ë°°ë‹¬ ë¡œë´‡ ì§€ë„"ì˜ˆìš”.
ë§¤ì¼ ì•„ì¹¨ 9ì‹œë§ˆë‹¤ ë¡œë´‡ ì¹œêµ¬ë“¤ì´ ê¹¨ì–´ë‚˜ì„œ ì¼ì„ ì‹œìž‘í•´ìš”.

ìš°ë¦¬ê°€ í•˜ë ¤ëŠ” ì¼ì€ 4ë‹¨ê³„ì˜ˆìš”:
1. ðŸ•µï¸ **ê³µê³  ìˆ˜ì§‘ (crawl_jobs_to_json)**: "ìƒˆë¡œìš´ ì¼ìžë¦¬ ì—†ë‚˜?" í•˜ê³  íƒì • ë¡œë´‡ì´ ì¸í„°ë„·ì„ ë’¤ì ¸ì„œ ê°€ì ¸ì™€ìš”.
2. ðŸ§  **ê³µë¶€ í•˜ê¸° (update_job_embeddings)**: "ì´ê±´ ì–´ë–¤ ì¼ì´ì§€?" í•˜ê³  ë˜‘ë˜‘í•œ ë¡œë´‡ì´ ê³µê³  ë‚´ìš©ì„ ê³µë¶€í•´ì„œ ë¨¸ë¦¿ì†ì— ì •ë¦¬í•´ìš”.
3. ðŸ­ **í™ˆíŽ˜ì´ì§€ ì§“ê¸° (build_static_site)**: ì‚¬ëžŒë“¤ì´ ë³¼ ìˆ˜ ìžˆê²Œ ì˜ˆìœ í™ˆíŽ˜ì´ì§€ë¥¼ ë§Œë“¤ì–´ìš”.
4. ðŸ“¬ **íŽ¸ì§€ ë³´ë‚´ê¸° (match_and_notify_users)**: "ì—¬ê¸° ë”± ë§žëŠ” ì¼ìžë¦¬ê°€ ìžˆì–´ìš”!" í•˜ê³  ê¸°ë‹¤ë¦¬ë˜ ì‚¬ëžŒë“¤ì—ê²Œ ì•Œë ¤ì¤˜ìš”.

ìž, ì´ì œ ë¡œë´‡ë“¤ì„ ë§Œë‚˜ë³¼ê¹Œìš”?
"""
from airflow import DAG
import pendulum
from datetime import datetime, timedelta
from airflow.providers.standard.operators.python import PythonOperator
import sys
import os

# Import Wrapper Functions
# ë¡œë´‡ë“¤ì´ ì‹¤ì œë¡œ í•  ì¼ì„ ì ì–´ë‘” ì±…(ë¼ì´ë¸ŒëŸ¬ë¦¬)ì„ ê°€ì ¸ì™€ìš”.
try:
    from src.pipeline_wrappers import (
        run_crawl_json,
        run_update_embeddings,
        run_build_static,
        run_match_profiles,
    )
except ImportError:
    # ë¡œì»¬ ê°œë°œ í™˜ê²½ì´ë‚˜ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ Mock í•¨ìˆ˜ë¥¼ ì¤€ë¹„í–ˆì–´ìš”.
    print("Warning: src.pipeline_wrappers not found. Using mocks.")
    run_crawl_json = lambda: print("Mock: Crawling jobs...")
    run_update_embeddings = lambda: print("Mock: Updating embeddings...")
    run_build_static = lambda: print("Mock: Building site...")
    run_match_profiles = lambda **kwargs: print("Mock: Matching profiles...")


# Default arguments
# ë¡œë´‡ë“¤ì˜ ê¸°ë³¸ ì•½ì†ì´ì—ìš”.
default_args = {
    "owner": "geon_yul",
    "retries": 1,                      # ì‹¤ìˆ˜í•˜ë©´ 1ë²ˆ ë” í•´ë´ìš”.
    "retry_delay": timedelta(seconds=600), # 10ë¶„ ì‰¬ì—ˆë‹¤ê°€ ë‹¤ì‹œ í•´ìš”.
}

# Pipeline Definition
# "ì±„ìš© ê³µê³  ë°°ë‹¬" ì§€ë„ë¥¼ íŽ¼ì¹©ë‹ˆë‹¤!
with DAG(
    dag_id="pipeline__recruitment_auto",
    default_args=default_args,
    schedule="0 9 * * *",              # ë§¤ì¼ ì•„ì¹¨ 9ì‹œì— ì•ŒëžŒì´ ìš¸ë ¤ìš”!
    catchup=False,
    tags=["recruitment", "automation"],
) as dag:

    # ==========================================================================
    # 1. ê³µê³  ìˆ˜ì§‘ íƒì • (Crawler)
    # ==========================================================================
    crawl_jobs_to_json = PythonOperator(
        task_id="crawl_jobs_to_json",
        python_callable=run_crawl_json,
        doc_md="""
        ### ðŸ•µï¸ ê³µê³  ìˆ˜ì§‘
        ì¸í„°ë„·ì—ì„œ ì±„ìš© ê³µê³ ë¥¼ ê¸ì–´ì™€ì„œ `jobs.json` íŒŒì¼ë¡œ ë§Œë“¤ì–´ìš”.
        """,
    )

    # ==========================================================================
    # 2. ë˜‘ë˜‘í•œ ê³µë¶€ë²Œë ˆ (Embedding)
    # ==========================================================================
    update_job_embeddings = PythonOperator(
        task_id="update_job_embeddings",
        python_callable=run_update_embeddings,
        doc_md="""
        ### ðŸ§  ìž„ë² ë”© ì—…ë°ì´íŠ¸
        ìƒˆë¡œ ê°€ì ¸ì˜¨ ê³µê³ ë¥¼ ìž˜ ê²€ìƒ‰í•  ìˆ˜ ìžˆê²Œ ìˆ«ìžë¡œ ë³€í™˜(Vectorizing)í•´ìš”.
        """,
    )

    # ==========================================================================
    # 3. í™ˆíŽ˜ì´ì§€ ê±´ì¶•ê°€ (Builder)
    # ==========================================================================
    build_static_site = PythonOperator(
        task_id="build_static_site",
        python_callable=run_build_static,
        doc_md="""
        ### ðŸ­ ì •ì  ì‚¬ì´íŠ¸ ë¹Œë“œ
        GitHub Pagesì— ì˜¬ë¦´ ì›¹ì‚¬ì´íŠ¸ íŒŒì¼ë“¤ì„ ë§Œë“¤ì–´ìš”.
        """,
    )

    # ==========================================================================
    # 4. ìš°íŽ¸ ë°°ë‹¬ë¶€ (Notifier)
    # ==========================================================================
    match_and_notify_users = PythonOperator(
        task_id="match_and_notify_users",
        python_callable=run_match_profiles,
        op_kwargs={"all_profiles": True}, # "ëª¨ë“  ì‚¬ëžŒì—ê²Œ ë‹¤ ì•Œë ¤ì¤˜!" ë¼ê³  ì£¼ë¬¸í–ˆì–´ìš”.
        doc_md="""
        ### ðŸ“¬ ë§¤ì¹­ ë° ì•Œë¦¼
        ì‚¬ëžŒë“¤ì˜ í”„ë¡œí•„ê³¼ ê³µê³ ë¥¼ ë¹„êµí•´ì„œ ë”± ë§žëŠ” ê±¸ ì°¾ì•„ì„œ Issue ëŒ“ê¸€ì„ ë‹¬ì•„ì¤˜ìš”.
        """,
    )

    # ==========================================================================
    # 5. ìˆœì„œ ì •í•˜ê¸° (Dependencies)
    # ==========================================================================
    
    # ìˆœì„œëŒ€ë¡œ ì°©ì°©ì°©!
    # ìˆ˜ì§‘ -> ê³µë¶€ -> (í™ˆíŽ˜ì´ì§€ ë§Œë“¤ê¸°, íŽ¸ì§€ ë³´ë‚´ê¸°) 
    
    crawl_jobs_to_json >> update_job_embeddings
    
    update_job_embeddings >> build_static_site
    update_job_embeddings >> match_and_notify_users
